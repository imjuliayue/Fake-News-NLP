### Description
Found data on Kaggle
Cleaned data on Kaggle for better tokenization
- remove punctuation
- lemmatize
- remove filler words
- same capitalization
Visualized data (better understanding of data)
- word cloud
- word frequency
- title length frequency
- text length frequency

Split data into train and test (80-20 split)

To do:
- Visualize dates and subject
- Use logistic regression
- Use SVM
- Use Ngrams
- build LLM or transformer
- Fine tune better models
